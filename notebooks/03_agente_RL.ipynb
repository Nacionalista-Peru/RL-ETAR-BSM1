{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erickcori/RL-ETAR-BSM1/blob/main/notebooks/03_agente_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMqlJIWKDFzz"
      },
      "outputs": [],
      "source": [
        "# Entrenamiento de Agente RL\n",
        "# Este notebook prepara y entrena un agente de aprendizaje por refuerzo (PPO/DQN) usando la simulación del BSM1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento de Agente RL\n",
        "# Este notebook prepara y entrena un agente de aprendizaje por refuerzo (PPO) usando la simulación del BSM1 (modo demostración).\n",
        "\n",
        "# Instalar librerías necesarias\n",
        "!pip install stable-baselines3[extra] optuna -q\n",
        "\n"
      ],
      "metadata": {
        "id": "wET5AGnGJQTQ",
        "outputId": "5a82ad83-8964-417e-c760-57120579226b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/383.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from gym import spaces\n",
        "\n",
        "# Simulación simplificada del BSM1 (mock)\n",
        "class BSM1Env(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(BSM1Env, self).__init__()\n",
        "        self.action_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)  # Control de oxígeno\n",
        "        self.observation_space = spaces.Box(low=0, high=100, shape=(4,), dtype=np.float32)  # DQO, NH4, NO3, SRT\n",
        "        self.state = np.array([50.0, 10.0, 5.0, 8.0], dtype=np.float32)\n",
        "        self.t = 0\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.state = np.array([50.0, 10.0, 5.0, 8.0], dtype=np.float32)\n",
        "        self.t = 0\n",
        "        return self.state, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        oxigeno = action[0]\n",
        "        self.state += np.random.normal(0, 0.5, size=self.state.shape) - oxigeno\n",
        "        reward = -np.sum(np.square(self.state - np.array([30, 5, 2, 5])))\n",
        "        self.t += 1\n",
        "        done = self.t >= 96\n",
        "        return self.state, reward, done, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Step {self.t}, State: {self.state}\")"
      ],
      "metadata": {
        "id": "KdhisLNA0h0u"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar librerías necesarias\n",
        "!pip install gymnasium stable-baselines3[extra] optuna -q\n",
        "\n",
        "# Imports\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from gymnasium import spaces\n",
        "\n",
        "# Simulación simplificada del BSM1 (mock)\n",
        "class BSM1Env(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(BSM1Env, self).__init__()\n",
        "        self.action_space = spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)  # Control de oxígeno\n",
        "        self.observation_space = spaces.Box(low=0, high=100, shape=(4,), dtype=np.float32)  # DQO, NH4, NO3, SRT\n",
        "        self.state = np.array([50.0, 10.0, 5.0, 8.0], dtype=np.float32)\n",
        "        self.t = 0\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.state = np.array([50.0, 10.0, 5.0, 8.0], dtype=np.float32)\n",
        "        self.t = 0\n",
        "        return self.state, {}\n",
        "\n",
        "    def step(self, action):\n",
        "        oxigeno = action[0]\n",
        "        self.state += np.random.normal(0, 0.5, size=self.state.shape) - oxigeno\n",
        "        reward = -np.sum(np.square(self.state - np.array([30, 5, 2, 5])))  # Penaliza desviación del estado deseado\n",
        "        self.t += 1\n",
        "        done = self.t >= 96\n",
        "        return self.state, reward, done, False, {}\n",
        "\n",
        "    def render(self):\n",
        "        print(f\"Step {self.t}, State: {self.state}\")\n",
        "\n",
        "# Crear y verificar el entorno\n",
        "env = BSM1Env()\n",
        "check_env(env)\n",
        "\n",
        "# Entrenar el agente PPO\n",
        "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
        "model.learn(total_timesteps=5000)\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "model.save(\"ppo_bsm1_agent\")\n",
        "\n",
        "# Probar el agente entrenado\n",
        "obs, _ = env.reset()\n",
        "for i in range(24):\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "    env.render()\n",
        "    if done:\n",
        "        break"
      ],
      "metadata": {
        "id": "SnstKNwjLDDo",
        "outputId": "0c90b68a-e049-472e-f6c4-ddb60dc8ac18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/env_checker.py:462: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 96        |\n",
            "|    ep_rew_mean     | -7.77e+04 |\n",
            "| time/              |           |\n",
            "|    fps             | 1339      |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 1         |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 96           |\n",
            "|    ep_rew_mean          | -7.71e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 921          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 4            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008883655 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | -5.26e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.98e+07     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00104     |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 2.17e+08     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 96           |\n",
            "|    ep_rew_mean          | -7.34e+04    |\n",
            "| time/                   |              |\n",
            "|    fps                  | 862          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018390948 |\n",
            "|    clip_fraction        | 0.000146     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 4.35e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.32e+08     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00184     |\n",
            "|    std                  | 0.998        |\n",
            "|    value_loss           | 2.11e+08     |\n",
            "------------------------------------------\n",
            "Step 1, State: [49.832756   9.109543   3.2845795  7.48268  ]\n",
            "Step 2, State: [49.17955    8.335335   2.8530598  5.996062 ]\n",
            "Step 3, State: [49.267715   7.904511   2.7557056  5.583593 ]\n",
            "Step 4, State: [49.014435   8.414685   2.4200442  5.443021 ]\n",
            "Step 5, State: [49.40087    7.9383183  2.5549102  5.211885 ]\n",
            "Step 6, State: [48.91814    8.481824   1.6235105  4.342128 ]\n",
            "Step 7, State: [48.03867    8.222701   1.0036777  3.3446233]\n",
            "Step 8, State: [48.399437   8.089094   0.5935541  2.9537106]\n",
            "Step 9, State: [47.859905    7.468729    0.16130322  2.8906164 ]\n",
            "Step 10, State: [48.262535   7.5984893 -0.6199995  2.8825066]\n",
            "Step 11, State: [48.34022     8.134277   -0.35285258  2.894305  ]\n",
            "Step 12, State: [4.9192154e+01 7.2657552e+00 3.8754161e-02 3.8704579e+00]\n",
            "Step 13, State: [49.062855   6.9300575 -0.7089376  3.2551038]\n",
            "Step 14, State: [48.893826  5.80192  -1.909853  2.038307]\n",
            "Step 15, State: [47.94462    5.9679384 -1.9074426  1.6244949]\n",
            "Step 16, State: [47.574715   5.4275055 -2.145201   0.875839 ]\n",
            "Step 17, State: [47.35146     5.9203596  -2.5509133   0.62861115]\n",
            "Step 18, State: [46.511597   4.641322  -3.794265  -0.6302056]\n",
            "Step 19, State: [46.462845   3.4341874 -4.35391   -1.0558914]\n",
            "Step 20, State: [45.382336   2.2502372 -5.036161  -1.5615903]\n",
            "Step 21, State: [44.265774  1.544766 -5.48014  -3.177921]\n",
            "Step 22, State: [44.556988   1.5212882 -6.473886  -3.5427842]\n",
            "Step 23, State: [44.924152   1.996073  -6.771735  -4.1885276]\n",
            "Step 24, State: [44.853714   1.7439823 -6.243319  -3.8614268]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"ppo_bsm1_agent.zip\")"
      ],
      "metadata": {
        "id": "zwZt40lh148H",
        "outputId": "463ef3f6-617a-427d-d6c7-7f3d9ef0e336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_305fa805-3a43-4e3f-b6a5-71cfa5f40580\", \"ppo_bsm1_agent.zip\", 141448)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}